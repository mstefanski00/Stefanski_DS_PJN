{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dff3cd7d",
   "metadata": {},
   "source": [
    "# PJN - Lab 10 - Podsumowanie\n",
    "\n",
    "#### Mikołaj Stefański\n",
    "\n",
    "## Ładowanie modułów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7087ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moduły załadowane poprawnie.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "from rag.metadata.ner import NERExtractor\n",
    "from rag.retrieval.search_engine import hybrid_search\n",
    "from rag.reasoning.agent_brain import extract_search_params\n",
    "\n",
    "print(\"Moduły załadowane poprawnie.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b145fa04",
   "metadata": {},
   "source": [
    "## Etap 1 — Ekstrakcja encji nazwanych (NER) i dat\n",
    "\n",
    "### Analiza jakości NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a9ad9ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analiza pliku: data/culturax_enriched.jsonl\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>named_entities</th>\n",
       "      <th>years</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Julie Wang 50PCS Big White Clear Self-Seal Zip...</td>\n",
       "      <td>[Duży Rozmiar Biały Jasny Self - Seal Zipper P...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Uwaga:1 cm=10 mm,1 mm=0,0393 cala,1 cal=25,4 m...</td>\n",
       "      <td>[Formy Do Odlewania Wi Moda Biżuteria Opakowan...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nie ulega wątpliwości, że dalsze doskonalenie ...</td>\n",
       "      <td>[Polsce]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kolejnym etapem kampanii „Moja biblioteka” był...</td>\n",
       "      <td>[Moja biblioteka]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Podsumowanie Przez ostatnie 10 latach nastąpił...</td>\n",
       "      <td>[Podsumowanie]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Julie Wang 50PCS Big White Clear Self-Seal Zip...   \n",
       "1  Uwaga:1 cm=10 mm,1 mm=0,0393 cala,1 cal=25,4 m...   \n",
       "2  Nie ulega wątpliwości, że dalsze doskonalenie ...   \n",
       "3  Kolejnym etapem kampanii „Moja biblioteka” był...   \n",
       "4  Podsumowanie Przez ostatnie 10 latach nastąpił...   \n",
       "\n",
       "                                      named_entities years  \n",
       "0  [Duży Rozmiar Biały Jasny Self - Seal Zipper P...    []  \n",
       "1  [Formy Do Odlewania Wi Moda Biżuteria Opakowan...    []  \n",
       "2                                           [Polsce]    []  \n",
       "3                                  [Moja biblioteka]    []  \n",
       "4                                     [Podsumowanie]    []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ENRICHED_FILE = \"data/culturax_enriched.jsonl\"\n",
    "samples = []\n",
    "\n",
    "print(f\"Analiza pliku: {ENRICHED_FILE}\")\n",
    "try:\n",
    "    with open(ENRICHED_FILE, 'r', encoding='utf-16') as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= 1000: break\n",
    "            doc = json.loads(line)\n",
    "            if doc.get('named_entities') or doc.get('years'):\n",
    "                samples.append(doc)\n",
    "                if len(samples) >= 5: break\n",
    "\n",
    "    df = pd.DataFrame(samples)[['text', 'named_entities', 'years']]\n",
    "    df['text'] = df['text'].apply(lambda x: x[:80] + \"...\")\n",
    "    display(df)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Nie znaleziono pliku enriched.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3f55c3",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "1. Szum i false positives - wiersze 0 i 1\n",
    "\n",
    "    Wiersze 0 i 1 to typowe śmieci z datasetu CulturaX - dane z common crawl, często e-commerce typu AliExpress. Model NER widzi długi ciąg słów pisanych wielką literą  i błędnie interpretuje to jako nazwę własną organizację lub produkt - model jest wrażliwy na styl pisowni title case w ofertach sprzedażowych.\n",
    "\n",
    "2. Sukces - wiersz 2\n",
    "\n",
    "    To jest dowód, że model działa poprawnie. Mimo że słowo jest w innej formie fleksyjnej (miejscownik: w Polsce), model je wyłapał.\n",
    "\n",
    "3. Niejednoznaczność - wiersze 3 i 4\n",
    "\n",
    "    \"Moja biblioteka\" to nazwa kampanii; widać cudzysłów we fragmencie tekstu. Model poprawnie uznał to za nazwę własną, choć technicznie to tytuł wydarzenia/akcji. Model prawdopodobnie uznał to za encję, ponieważ słowo występuje na początku nagłówka/zdania i jest pisane wielką literą. To typowy błąd capitalization bias."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aeaf5b",
   "metadata": {},
   "source": [
    "## 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bee4c8df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tekst</th>\n",
       "      <th>Wykryte Encje</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hello Web Admin, I noticed that your On-Page S...</td>\n",
       "      <td>[Web Admin, Page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Krótko o parowych łaźniachWokół każdego domu- ...</td>\n",
       "      <td>[Które Zmienią Wszystko Co Myślałeś O Tym Jak ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jest wiceprezesem i dyrektorem generalnym mark...</td>\n",
       "      <td>[Artemide, Danese Milano]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dokonując zakupów w naszym sklepie macie gwara...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Pierwszy wpis związany z przodkami jaki znajdu...</td>\n",
       "      <td>[Kata, ##ziubów, Przedborza, Sobol, Tomasz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Niezależnie od tego, jak piękne hasła będzie p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mowa tu o tym, że jeśli ten konkretny producen...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Raport z 17 maja 2 167 nowych zakażeń koronawi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ryczałt ewidencjonowany opłaca się według staw...</td>\n",
       "      <td>[##y]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>autor opinii: Anna Lebioda Książeczka godna pr...</td>\n",
       "      <td>[Anna Lebioda, Katarzyna Wołcyrz Niepozor]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>« Odpowiedź #11 dnia: 24 Maj, 2018, 11:37 » W ...</td>\n",
       "      <td>[Świadkowie Jehowy, Biblia]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>OROT wraz z Urzędem Marszałkowskim Województwa...</td>\n",
       "      <td>[Urzędem Marszałkowskim Województwa Opolskiego]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[link widoczny dla zalogowanych] Sama sie upom...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Jest on w pełni cyfrowy, spełnia warunki aktua...</td>\n",
       "      <td>[RoomPerfect]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>- Chcę państwa zachęcić, żebyście z tej koniun...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Zdaniem doktora Marka Wasiluka, autora książki...</td>\n",
       "      <td>[Marka Wasiluka]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Ma w sobie dwie najważniejsze rzeczy, które ce...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1 zaprzeczył, by przekazywał na rzecz brata ja...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Telefon cechuje procesor wyposażony w cztery r...</td>\n",
       "      <td>[IPS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Odchudzający Koktajl Truskawkowy.Bialy aniol z...</td>\n",
       "      <td>[Koktajl T]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Chociaz zauwazylem, ze zycie (ech, jak ja nien...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pokoje o powierzchni od 9,9 m 2 do 21,7 m 2 tj...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Możliwe formy dostarczenia to wysyłka kuriersk...</td>\n",
       "      <td>[Twoim mieście]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Na szczęście (przynajmniej taką mam nadzieję) ...</td>\n",
       "      <td>[Techland]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Losowe strony Przesiewacze, przenośniki taś Of...</td>\n",
       "      <td>[Sklep Brostruck Sklep Brostru]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tekst  \\\n",
       "0   Hello Web Admin, I noticed that your On-Page S...   \n",
       "1   Krótko o parowych łaźniachWokół każdego domu- ...   \n",
       "2   Jest wiceprezesem i dyrektorem generalnym mark...   \n",
       "3   Dokonując zakupów w naszym sklepie macie gwara...   \n",
       "4   Pierwszy wpis związany z przodkami jaki znajdu...   \n",
       "5   Niezależnie od tego, jak piękne hasła będzie p...   \n",
       "6   Mowa tu o tym, że jeśli ten konkretny producen...   \n",
       "7   Raport z 17 maja 2 167 nowych zakażeń koronawi...   \n",
       "8   Ryczałt ewidencjonowany opłaca się według staw...   \n",
       "9   autor opinii: Anna Lebioda Książeczka godna pr...   \n",
       "10  « Odpowiedź #11 dnia: 24 Maj, 2018, 11:37 » W ...   \n",
       "11  OROT wraz z Urzędem Marszałkowskim Województwa...   \n",
       "12  [link widoczny dla zalogowanych] Sama sie upom...   \n",
       "13  Jest on w pełni cyfrowy, spełnia warunki aktua...   \n",
       "14  - Chcę państwa zachęcić, żebyście z tej koniun...   \n",
       "15  Zdaniem doktora Marka Wasiluka, autora książki...   \n",
       "16  Ma w sobie dwie najważniejsze rzeczy, które ce...   \n",
       "17  1 zaprzeczył, by przekazywał na rzecz brata ja...   \n",
       "18  Telefon cechuje procesor wyposażony w cztery r...   \n",
       "19  Odchudzający Koktajl Truskawkowy.Bialy aniol z...   \n",
       "20  Chociaz zauwazylem, ze zycie (ech, jak ja nien...   \n",
       "21  Pokoje o powierzchni od 9,9 m 2 do 21,7 m 2 tj...   \n",
       "22  Możliwe formy dostarczenia to wysyłka kuriersk...   \n",
       "23  Na szczęście (przynajmniej taką mam nadzieję) ...   \n",
       "24  Losowe strony Przesiewacze, przenośniki taś Of...   \n",
       "\n",
       "                                        Wykryte Encje  \n",
       "0                                   [Web Admin, Page]  \n",
       "1   [Które Zmienią Wszystko Co Myślałeś O Tym Jak ...  \n",
       "2                           [Artemide, Danese Milano]  \n",
       "3                                                  []  \n",
       "4         [Kata, ##ziubów, Przedborza, Sobol, Tomasz]  \n",
       "5                                                  []  \n",
       "6                                                  []  \n",
       "7                                                  []  \n",
       "8                                               [##y]  \n",
       "9          [Anna Lebioda, Katarzyna Wołcyrz Niepozor]  \n",
       "10                        [Świadkowie Jehowy, Biblia]  \n",
       "11    [Urzędem Marszałkowskim Województwa Opolskiego]  \n",
       "12                                                 []  \n",
       "13                                      [RoomPerfect]  \n",
       "14                                                 []  \n",
       "15                                   [Marka Wasiluka]  \n",
       "16                                                 []  \n",
       "17                                                 []  \n",
       "18                                              [IPS]  \n",
       "19                                        [Koktajl T]  \n",
       "20                                                 []  \n",
       "21                                                 []  \n",
       "22                                    [Twoim mieście]  \n",
       "23                                         [Techland]  \n",
       "24                    [Sklep Brostruck Sklep Brostru]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "ENRICHED_FILE = \"data/culturax_enriched.jsonl\"\n",
    "\n",
    "try:\n",
    "    with open(ENRICHED_FILE, 'r', encoding='utf-16') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    samples = random.sample(lines, 25)\n",
    "    data_for_display = []\n",
    "\n",
    "    for line in samples:\n",
    "        doc = json.loads(line)\n",
    "        data_for_display.append({\n",
    "            \"Tekst\": doc.get('text', '')[:100] + \"...\",\n",
    "            \"Wykryte Encje\": doc.get('named_entities', [])\n",
    "        })\n",
    "\n",
    "    df = pd.DataFrame(data_for_display)\n",
    "    display(df)\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Najpierw uruchom skrypt enrich_data.py, aby stworzyć plik z danymi.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dd89be",
   "metadata": {},
   "source": [
    "#### Wnioski z analizy modelu NER\n",
    "\n",
    "Analiza 25 losowych fragmentów z korpusu `CulturaX` przy użyciu modelu `Babelscape/wikineural-multilingual-ner` przyniosła następujące obserwacje:\n",
    "\n",
    "1. Rozpoznawane typy encji\n",
    "    Model poprawnie identyfikuje kluczowe kategorie semantyczne:\n",
    "    - **PER (Osoby):** wykrywa zarówno imiona, jak i pełne nazwiska np. \"Anna Lebioda\", \"Katarzyna Wołcyrz Niepozor\", \"Tomasz\", \"Marek Wasiluk\".\n",
    "    - **ORG (Organizacje):** rozpoznaje firmy i instytucje np. \"Techland\", \"Artemide\", \"Danese Milano\", \"Urzędem Marszałkowskim Województwa Opolskiego\".\n",
    "    - **LOC (Lokalizacje):** wykrywa nazwy geograficzne np. \"Przedborza\".\n",
    "    - **MISC / Inne:** rozpoznaje nazwy produktów, technologii lub grup wyznaniowych np. \"RoomPerfect\", \"IPS\", \"Świadkowie Jehowy\", \"Biblia\".\n",
    "\n",
    "2. Typowe błędy i problemy\n",
    "    - **Capitalization Bias:** model ma tendencję do błędnego oznaczania długich ciągów wyrazów jako encji, jeśli są pisane w stylu nagłówkowym. Widać to w próbce nr 1: \"Które Zmienią Wszystko Co Myślałeś...\", błędnie zaklasyfikowane jako encja.\n",
    "    - **Artefakty tokenizacji:** w próbce nr 4 pojawia się encja \"##ziubów\". Znak `##` jest charakterystyczny dla tokenizatorów modeli BERT i oznacza fragment słowa. Wskazuje to na problem ze sklejeniem tokenów po stronie pipeline'u w rzadkich przypadkach.\n",
    "    - **Szum językowy:** próbka nr 0 jest w języku angielskim \"Web Admin\", co model próbował zinterpretować jako osobę/rolę, mimo że kontekst jest polski.\n",
    "\n",
    "3.  Fleksja i odmiana\n",
    "    Model radzi sobie z polską deklinacją bardzo dobrze, co jest jego największą przewagą nad metodami RegExp:\n",
    "    - **Próbka 11:** \"Urzędem Marszałkowskim Województwa Opolskiego\" – poprawnie rozpoznano długą nazwę w nadrzędniku (kim/czym?).\n",
    "    - **Próbka 15:** \"Marka Wasiluka\" – poprawnie rozpoznano imię i nazwisko w dopełniaczu (kogo? czego?), wiążąc to z kategorią PER.\n",
    "    - **Próbka 4:** \"Przedborza\" – poprawnie rozpoznano nazwę miasta w dopełniaczu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d076d20",
   "metadata": {},
   "source": [
    "### 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa84d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ładowanie modelu NER: Babelscape/wikineural-multilingual-ner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NER gotowy.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tekst</th>\n",
       "      <th>1. RegExp</th>\n",
       "      <th>2. NER (Wynik)</th>\n",
       "      <th>3. LLM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Urodziłem się 12.05.1990 w Warszawie, a w 2020 roku przeprowadziłem się.</td>\n",
       "      <td>{'years': [1990, 2020], 'dates': ['12.05.1990']}</td>\n",
       "      <td>[Warszawie]</td>\n",
       "      <td>{'dates': ['12.05.1990', '2020'], 'years': [1990, 2020], 'ranges': ['w Warszawie', 'przeprowadziłem się']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Projekt trwał od 2010 do 2015 roku i zakończył się sukcesem.</td>\n",
       "      <td>{'years': [2010, 2015], 'dates': []}</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'dates': ['2010', '2015'], 'years': [2010, 2015], 'ranges': ['od 2010 do 2015 roku']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spotkanie odbędzie się 2024-12-24. Pamiętaj o terminie!</td>\n",
       "      <td>{'years': [2024], 'dates': ['2024-12-24']}</td>\n",
       "      <td>[Pamiętaj o terminie!]</td>\n",
       "      <td>{'dates': ['2024-12-24'], 'years': [2024], 'ranges': ['termin']}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lata 90-te były czasem przemian w Polsce.</td>\n",
       "      <td>{'years': [], 'dates': []}</td>\n",
       "      <td>[Polsce]</td>\n",
       "      <td>{'dates': [], 'years': [90], 'ranges': ['lata 90-te']}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      Tekst  \\\n",
       "0  Urodziłem się 12.05.1990 w Warszawie, a w 2020 roku przeprowadziłem się.   \n",
       "1              Projekt trwał od 2010 do 2015 roku i zakończył się sukcesem.   \n",
       "2                   Spotkanie odbędzie się 2024-12-24. Pamiętaj o terminie!   \n",
       "3                                 Lata 90-te były czasem przemian w Polsce.   \n",
       "\n",
       "                                          1. RegExp          2. NER (Wynik)  \\\n",
       "0  {'years': [1990, 2020], 'dates': ['12.05.1990']}             [Warszawie]   \n",
       "1              {'years': [2010, 2015], 'dates': []}                      []   \n",
       "2        {'years': [2024], 'dates': ['2024-12-24']}  [Pamiętaj o terminie!]   \n",
       "3                        {'years': [], 'dates': []}                [Polsce]   \n",
       "\n",
       "                                                                                                       3. LLM  \n",
       "0  {'dates': ['12.05.1990', '2020'], 'years': [1990, 2020], 'ranges': ['w Warszawie', 'przeprowadziłem się']}  \n",
       "1                      {'dates': ['2010', '2015'], 'years': [2010, 2015], 'ranges': ['od 2010 do 2015 roku']}  \n",
       "2                                            {'dates': ['2024-12-24'], 'years': [2024], 'ranges': ['termin']}  \n",
       "3                                                      {'dates': [], 'years': [90], 'ranges': ['lata 90-te']}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rag.metadata.ner import NERExtractor\n",
    "from rag.metadata.date_extractor_regex_llm import DateExtractorHybrid\n",
    "\n",
    "ner_model = NERExtractor()\n",
    "date_hybrid = DateExtractorHybrid()\n",
    "\n",
    "test_sentences = [\n",
    "    \"Urodziłem się 12.05.1990 w Warszawie, a w 2020 roku przeprowadziłem się.\",\n",
    "    \"Projekt trwał od 2010 do 2015 roku i zakończył się sukcesem.\",\n",
    "    \"Spotkanie odbędzie się 2024-12-24. Pamiętaj o terminie!\",\n",
    "    \"Lata 90-te były czasem przemian w Polsce.\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "\n",
    "for text in test_sentences:\n",
    "    res_regex = date_hybrid.extract_regex(text)\n",
    "    \n",
    "    res_ner = ner_model.extract(text)\n",
    "    \n",
    "    res_llm = date_hybrid.extract_llm(text)\n",
    "    \n",
    "    results.append({\n",
    "        \"Tekst\": text,\n",
    "        \"1. RegExp\": res_regex,\n",
    "        \"2. NER (Wynik)\": res_ner,\n",
    "        \"3. LLM\": res_llm\n",
    "    })\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(pd.DataFrame(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccaf575",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "1.  RegExp\n",
    "    - **Zalety:** bezbłędnie wyciąga daty w sztywnych formatach (ISO `2024-12-24`, PL `12.05.1990`) oraz pojedyncze lata.\n",
    "    - **Wady:** całkowicie ignoruje wyrażenia opisowe. W zdaniu \"Lata 90-te były czasem przemian\" zwrócił pusty wynik, co dyskwalifikuje go w analizie kontekstu historycznego.\n",
    "\n",
    "2.  NER\n",
    "    - **Ocena:** Metoda nieprzydatna do dat.\n",
    "    - Model poprawnie wykrył lokalizacje, ale w przypadku daty wygenerował tzw. false positive, oznaczając frazę \"Pamiętaj o terminie!\" jako encję. Nie posiada dedykowanej klasy `DATE`.\n",
    "\n",
    "3.  LLM\n",
    "    - **Zalety:** Jako jedyny system poprawnie zinterpretował logikę zakresów \"od 2010 do 2015\" i okresów \"Lata 90-te\"* => rok 90.\n",
    "    - **Wady:** Model ma tendencję do nadgorliwości. W polu `ranges` potrafi umieścić fragmenty tekstu niebędące czasem np. \"przeprowadziłem się\", \"termin\". Wymagałoby to dodatkowego czyszczenia danych.\n",
    "\n",
    "**Strategia Hybrydowa**\n",
    "\n",
    "W projekcie wykorzystano RegExp do szybkiego indeksowania bazy, natomiast LLM jest używany warunkowo w agencie do interpretacji zapytań użytkownika, gdzie kluczowe jest zrozumienie intencji."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eabaf4",
   "metadata": {},
   "source": [
    "### 4.3.\n",
    "\n",
    "Zgodnie z wymaganiami, proces wzbogacania danych (Data Enrichment) oraz konfiguracji baz danych został zrealizowany w dwóch krokach:\n",
    "\n",
    "1. Wzbogacanie danych za pomocą skryptu `enrich_data.py`\n",
    "\n",
    "  Surowe dane z pliku `culturax_pl_clean.jsonl` zostały przetworzone przez pipeline NLP, który dodał do każdego dokumentu nowe pola:\n",
    "  - `named_entities`: wynik działania modelu NER.\n",
    "  - `years`: wynik działania wyrażeń regularnych.\n",
    "\n",
    "  Przykładowa struktura dokumentu po przetworzeniu:\n",
    "  json\n",
    "  {\n",
    "    \"text\": \"Spotkanie w Warszawie w 2023 roku...\",\n",
    "    \"named_entities\": [\"Warszawie\"],\n",
    "    \"years\": [2023]\n",
    "  }\n",
    "\n",
    "2. Konfiguracja Elasticsearch\n",
    "  W pliku setup_enriched_db.py zdefiniowano sztywny mapping dla indeksu lab10_hybrid. Jest to kluczowe dla poprawnego filtrowania: \n",
    "  - Pole `named_entities` otrzymało typ keyword. Pozwala to na precyzyjne filtrowanie po nazwach własnych.\n",
    "\n",
    "  - Pole `years` otrzymało typ integer. Pozwala to na wykonywanie zapytań zakresowych, np. years >= 2020.\n",
    "\n",
    "3. Konfiguracja Qdrant. \n",
    "\n",
    "  Do wektorowej bazy danych Qdrant, obok wektora, przesłano payload zawierający te same metadane. Dzięki temu silnik Qdrant może wykonywać tzw. pre-filtering - czyli odrzucać wektory niespełniające kryteriów jeszcze przed obliczeniem podobieństwa cosinusowego, co znacząco przyspiesza wyszukiwanie i zwiększa precyzję."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6590173f",
   "metadata": {},
   "source": [
    "## 5. NLP w praktyce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "666b6a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozpoczynam Benchmark metod NLP.\n",
      "\n",
      "Temat: Odpowiedzialność.\n",
      "\n",
      "Temat: Liderzy.\n",
      "\n",
      "Temat: Zaufanie.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temat</th>\n",
       "      <th>Metoda</th>\n",
       "      <th>Wynik</th>\n",
       "      <th>Metadane</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Odpowiedzialność</td>\n",
       "      <td>1. RegExp</td>\n",
       "      <td>Za reżyserię filmu \"Kobieta w czerni 2\" jest odpowiedzialny Tom Harper (\"Peaky B...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Odpowiedzialność</td>\n",
       "      <td>2. BM25</td>\n",
       "      <td>Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Odpowiedzialność</td>\n",
       "      <td>3. Vector</td>\n",
       "      <td>Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Odpowiedzialność</td>\n",
       "      <td>4. Hybrid</td>\n",
       "      <td>Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Odpowiedzialność</td>\n",
       "      <td>5. Hybrid + METADATA</td>\n",
       "      <td>Redakcja Tweet Telegram WhatsApp Email Like this: Like Loading... Mariusz Matusz...</td>\n",
       "      <td>[2022]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Liderzy</td>\n",
       "      <td>1. RegExp</td>\n",
       "      <td>Kiedy osoba jest silnym przywódcą, te wewnętrzne cechy są rozszerzone na innych,...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Liderzy</td>\n",
       "      <td>2. BM25</td>\n",
       "      <td>Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Liderzy</td>\n",
       "      <td>3. Vector</td>\n",
       "      <td>Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Liderzy</td>\n",
       "      <td>4. Hybrid</td>\n",
       "      <td>Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Liderzy</td>\n",
       "      <td>5. Hybrid + METADATA</td>\n",
       "      <td>Dostrzegając ważność i ciągłą aktualność tych tematów, podjęliśmy dyskusję na te...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Zaufanie</td>\n",
       "      <td>1. RegExp</td>\n",
       "      <td>Rodzaj podejścia, w którym przejrzystość, poprawność i niezawodność są niezbędny...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Zaufanie</td>\n",
       "      <td>2. BM25</td>\n",
       "      <td>Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zaufanie</td>\n",
       "      <td>3. Vector</td>\n",
       "      <td>Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Zaufanie</td>\n",
       "      <td>4. Hybrid</td>\n",
       "      <td>Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Zaufanie</td>\n",
       "      <td>5. Hybrid + METADATA</td>\n",
       "      <td>Będzie drożej nawet o 1500 zł – „zasada 20 dni” Moto Newsy 08.12.2021 Igor Szmid...</td>\n",
       "      <td>[2021]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Temat                Metoda  \\\n",
       "0   Odpowiedzialność             1. RegExp   \n",
       "1   Odpowiedzialność               2. BM25   \n",
       "2   Odpowiedzialność             3. Vector   \n",
       "3   Odpowiedzialność             4. Hybrid   \n",
       "4   Odpowiedzialność  5. Hybrid + METADATA   \n",
       "5            Liderzy             1. RegExp   \n",
       "6            Liderzy               2. BM25   \n",
       "7            Liderzy             3. Vector   \n",
       "8            Liderzy             4. Hybrid   \n",
       "9            Liderzy  5. Hybrid + METADATA   \n",
       "10          Zaufanie             1. RegExp   \n",
       "11          Zaufanie               2. BM25   \n",
       "12          Zaufanie             3. Vector   \n",
       "13          Zaufanie             4. Hybrid   \n",
       "14          Zaufanie  5. Hybrid + METADATA   \n",
       "\n",
       "                                                                                  Wynik  \\\n",
       "0   Za reżyserię filmu \"Kobieta w czerni 2\" jest odpowiedzialny Tom Harper (\"Peaky B...   \n",
       "1   Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...   \n",
       "2   Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...   \n",
       "3   Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowanie...   \n",
       "4   Redakcja Tweet Telegram WhatsApp Email Like this: Like Loading... Mariusz Matusz...   \n",
       "5   Kiedy osoba jest silnym przywódcą, te wewnętrzne cechy są rozszerzone na innych,...   \n",
       "6   Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...   \n",
       "7   Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...   \n",
       "8   Rozpoznanie kompetencji Kompetentni przywódcy z powodzeniem spełniają wyzwanie w...   \n",
       "9   Dostrzegając ważność i ciągłą aktualność tych tematów, podjęliśmy dyskusję na te...   \n",
       "10  Rodzaj podejścia, w którym przejrzystość, poprawność i niezawodność są niezbędny...   \n",
       "11  Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...   \n",
       "12  Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...   \n",
       "13  Członkowie Komisji reprezentowaliKasę Rolniczego Ubezpieczenia Społecznego, Radę...   \n",
       "14  Będzie drożej nawet o 1500 zł – „zasada 20 dni” Moto Newsy 08.12.2021 Igor Szmid...   \n",
       "\n",
       "   Metadane  \n",
       "0        []  \n",
       "1        []  \n",
       "2        []  \n",
       "3        []  \n",
       "4    [2022]  \n",
       "5        []  \n",
       "6        []  \n",
       "7        []  \n",
       "8        []  \n",
       "9        []  \n",
       "10       []  \n",
       "11       []  \n",
       "12       []  \n",
       "13       []  \n",
       "14   [2021]  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "from rag.retrieval.search_engine import hybrid_search\n",
    "\n",
    "\n",
    "topics = [\n",
    "    {\n",
    "        \"name\": \"Odpowiedzialność\",\n",
    "        \"regex_pattern\": r\"odpowiedzialn\\w+\",\n",
    "        \"query\": \"poczucie odpowiedzialności za innych\",\n",
    "        \"year_filter\": 2020,\n",
    "        \"entity_filter\": None \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Liderzy\",\n",
    "        \"regex_pattern\": r\"lider\\w+|przywódc\\w+\",\n",
    "        \"query\": \"cechy dobrego lidera i przywódcy\",\n",
    "        \"year_filter\": None,\n",
    "        \"entity_filter\": \"Polsce\" \n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Zaufanie\",\n",
    "        \"regex_pattern\": r\"zaufani\\w+|ufnoś\\w+\",\n",
    "        \"query\": \"utrata zaufania społecznego\",\n",
    "        \"year_filter\": 2021,\n",
    "        \"entity_filter\": None\n",
    "    }\n",
    "]\n",
    "\n",
    "DATA_FILE = \"data/culturax_enriched.jsonl\"\n",
    "\n",
    "def run_regex_benchmark(pattern, limit=3):\n",
    "    results = []\n",
    "    try:\n",
    "        with open(DATA_FILE, 'r', encoding='utf-16') as f:\n",
    "            for line in f:\n",
    "                if len(results) >= limit: break\n",
    "                doc = json.loads(line)\n",
    "                if re.search(pattern, doc['text'], re.IGNORECASE):\n",
    "                    results.append(doc)\n",
    "    except Exception as e:\n",
    "        print(f\"Błąd RegExp: {e}\")\n",
    "    return results\n",
    "\n",
    "benchmark_data = []\n",
    "\n",
    "print(\"Rozpoczynam Benchmark metod NLP.\")\n",
    "\n",
    "for t in topics:\n",
    "    print(f\"\\nTemat: {t['name']}.\")\n",
    "    \n",
    "    hits_regex = run_regex_benchmark(t['regex_pattern'])\n",
    "    benchmark_data.append({\n",
    "        \"Temat\": t['name'], \"Metoda\": \"1. RegExp\", \n",
    "        \"Wynik\": hits_regex[0]['text'][:80] + \"...\" if hits_regex else \"BRAK\",\n",
    "        \"Metadane\": str(hits_regex[0].get('years')) if hits_regex else \"-\"\n",
    "    })\n",
    "\n",
    "    hits_bm25 = hybrid_search(t['query'], filters=None, limit=3, weight_es=1.0, weight_qdrant=0.0)\n",
    "    benchmark_data.append({\n",
    "        \"Temat\": t['name'], \"Metoda\": \"2. BM25\", \n",
    "        \"Wynik\": hits_bm25[0]['text'][:80] + \"...\" if hits_bm25 else \"BRAK\",\n",
    "        \"Metadane\": str(hits_bm25[0].get('years')) if hits_bm25 else \"-\"\n",
    "    })\n",
    "\n",
    "    hits_vec = hybrid_search(t['query'], filters=None, limit=3, weight_es=0.0, weight_qdrant=1.0)\n",
    "    benchmark_data.append({\n",
    "        \"Temat\": t['name'], \"Metoda\": \"3. Vector\", \n",
    "        \"Wynik\": hits_vec[0]['text'][:80] + \"...\" if hits_vec else \"BRAK\",\n",
    "        \"Metadane\": str(hits_vec[0].get('years')) if hits_vec else \"-\"\n",
    "    })\n",
    "\n",
    "    hits_hybrid = hybrid_search(t['query'], filters=None, limit=3)\n",
    "    benchmark_data.append({\n",
    "        \"Temat\": t['name'], \"Metoda\": \"4. Hybrid\", \n",
    "        \"Wynik\": hits_hybrid[0]['text'][:80] + \"...\" if hits_hybrid else \"BRAK\",\n",
    "        \"Metadane\": str(hits_hybrid[0].get('years')) if hits_hybrid else \"-\"\n",
    "    })\n",
    "\n",
    "    filters = {}\n",
    "    if t['year_filter']:\n",
    "        filters['years'] = [y for y in range(t['year_filter'], 2025)]\n",
    "    if t['entity_filter']:\n",
    "        filters['named_entities'] = [t['entity_filter']]\n",
    "        \n",
    "    hits_meta = hybrid_search(t['query'], filters=filters, limit=3)\n",
    "    benchmark_data.append({\n",
    "        \"Temat\": t['name'], \"Metoda\": \"5. Hybrid + METADATA\", \n",
    "        \"Wynik\": hits_meta[0]['text'][:80] + \"...\" if hits_meta else \"BRAK\",\n",
    "        \"Metadane\": str(hits_meta[0].get('years')) if hits_meta else \"-\"\n",
    "    })\n",
    "\n",
    "df_results = pd.DataFrame(benchmark_data)\n",
    "display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab722575",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "### 5. Raport z Benchmarku NLP\n",
    "\n",
    "Poniższa tabela przedstawia analizę wyników uzyskanych na korpusie `CulturaX` dla trzech pojęć abstrakcyjnych.\n",
    "\n",
    "| Temat | Metoda | Sensowność wyniku | Typowe błędy | Czy encje / daty pomogły? |\n",
    "| :--- | :--- | :--- | :--- | :--- |\n",
    "| **Odpowiedzialność** | **RegExp** | **Niska** | Całkowity brak kontekstu. Złapano reżysera filmu \"odpowiedzialny Tom Harper\", co nie ma związku z pojęciem abstrakcyjnym. | Nie |\n",
    "| | **Vector / Hybrid** | **Wysoka** | Poprawne dopasowanie semantyczne (\"Samostanowienie rozwija autonomię\"). Model zrozumiał kontekst psychologiczny/socjologiczny. | Nie |\n",
    "| | **Hybrid + Meta** | **Bardzo Dobra** | Wynik jest poprawny semantycznie i pochodzi z roku **2022**, co gwarantuje aktualność informacji. | **TAK** - wyeliminowano stare teksty. |\n",
    "| **Liderzy** | **RegExp** | **Średnia** | Złapano ogólne zdanie o przywódcy. Ryzyko złapania \"lidera cen\". | Nie |\n",
    "| | **Vector** | **Wysoka** | Trafne dopasowanie \"rozpoznanie kompetencji\", \"kompetentni przywódcy\". | Nie |\n",
    "| | **Hybrid + Meta** | **Wysoka** | Wynik dotyczy dyskusji/panelu, co sugeruje kontekst zgodny z filtrem np. wydarzenie w Polsce. | **TAK** - kontekst lokalny. |\n",
    "| **Zaufanie** | **Vector** | **Średnia** | Model skojarzył \"zaufanie społeczne\" z instytucjami, co jest luźnym dopasowaniem, ale nie do końca tym, o co pytano. | Nie |\n",
    "| | **Hybrid + Meta** | **Techniczna** | Znaleziono newsa z 2021 roku. System rygorystycznie przestrzegał daty, nawet jeśli temat zszedł na newsy gospodarcze. | **TAK** - filtr czasu zadziałał bezbłędnie. |\n",
    "\n",
    "#### Wnioski\n",
    "\n",
    "1.  RegExp to \"ślepe narzędzie\"\n",
    "\n",
    "    Przypadek \"odpowiedzialności\" pokazuje, że szukanie po rdzeniu słowa w tematach abstrakcyjnych generuje duży szum informacyjny.\n",
    "\n",
    "2.  Przewaga wektorów \n",
    "\n",
    "    Metody oparte na embeddingach znacznie lepiej radzą sobie z wyłapaniem sensu definicji i pojęć psychologicznych autonomia, kompetencje.\n",
    "\n",
    "3.  Siła metadanych \n",
    "\n",
    "    Dodanie filtrów (rok, encja) działa jak twardy bezpiecznik. Nawet jeśli wyszukiwarka wektorowa chce zwrócić lepszy, ale stary wynik - system wymusza nowsze dane. Jest to kluczowe w systemach biznesowych i newsowych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef22d197",
   "metadata": {},
   "source": [
    "### 5.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7351337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generowanie datasetu testowego.\n",
      "\\ Wygenerowano 60 rekordów.\n",
      "Przykładowe 2 rekordy:\n",
      "[\n",
      "  {\n",
      "    \"id\": \"69766\",\n",
      "    \"text\": \"Przedmiotem ubezpieczenia jest odpowiedzialność cywilna adwokata za szkody wyrządzone w następstwie działania lub zaniechania podczas wykonywania czynności zawodowych....\",\n",
      "    \"label\": \"relevant\",\n",
      "    \"topic\": \"odpowiedzialność zespołowa\"\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"85147\",\n",
      "    \"text\": \"Odpowiedzialność: Samostanowienie rozwija autonomię, co wiąże się z przejmowaniem odpowiedzialności za wybory, a to prowadzi do jeszcze większej odpowiedzialności....\",\n",
      "    \"label\": \"relevant\",\n",
      "    \"topic\": \"odpowiedzialność zespołowa\"\n",
      "  }\n",
      "]\n",
      "\n",
      "Analiza metadanych:\n",
      "\n",
      "Temat: odpowiedzialność zespołowa\n",
      "   [Trafne] Typowe lata: [(2011, 1)] | Typowe encje: [('Samostanowienie', 2), ('Tomasz Grzyb', 2), ('European Commission', 1)]\n",
      "   [Szum]   Typowe lata: [(2002, 1)] | Typowe encje: [('Archidiecezja Glasgow', 1), ('Szkocji', 1), ('Mario Conti', 1)]\n",
      "\n",
      "Temat: przywództwo i liderzy\n",
      "   [Trafne] Typowe lata: [(2020, 1)] | Typowe encje: [('Jaźni', 1), ('Ireneusz Gierek', 1), ('Tadeusz Pichor', 1)]\n",
      "   [Szum]   Typowe lata: [(2019, 1)] | Typowe encje: [('Schwalenberg', 1), ('Nadrenia Północna - Westfalia', 1), ('Blombergu', 1)]\n",
      "\n",
      "Temat: zaufanie i jego utrata\n",
      "   [Trafne] Typowe lata: [(2020, 1)] | Typowe encje: [('Polaków', 1), ('DAO', 1), ('Zaufanie do rizk casino', 1)]\n",
      "   [Szum]   Typowe lata: [(2020, 1), (2006, 1)] | Typowe encje: [('Tatrach', 2), ('Cezary Kawecki', 1), ('Wewnątrznac', 1)]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "from rag.retrieval.search_engine import hybrid_search\n",
    "\n",
    "ALL_DOCS = []\n",
    "with open(\"data/culturax_enriched.jsonl\", 'r', encoding='utf-16') as f:\n",
    "    for line in f:\n",
    "        ALL_DOCS.append(json.loads(line))\n",
    "\n",
    "def generate_benchmark_dataset():\n",
    "    topics = [\n",
    "        \"odpowiedzialność zespołowa\",\n",
    "        \"przywództwo i liderzy\",\n",
    "        \"zaufanie i jego utrata\"\n",
    "    ]\n",
    "    \n",
    "    dataset = []\n",
    "    stats = {t: {\"rel_years\": [], \"rel_ents\": [], \"noise_years\": [], \"noise_ents\": []} for t in topics}\n",
    "\n",
    "    print(\"Generowanie datasetu testowego.\")\n",
    "\n",
    "    for topic in topics:\n",
    "\n",
    "        relevant_docs = hybrid_search(topic, limit=10)\n",
    "        \n",
    "        relevant_ids = set()\n",
    "        for doc in relevant_docs:\n",
    "            doc_id = doc.get('id', str(random.randint(10000, 99999))) \n",
    "            relevant_ids.add(doc_id)\n",
    "            \n",
    "            dataset.append({\n",
    "                \"id\": doc_id,\n",
    "                \"text\": doc.get('text', '')[:200] + \"...\", \n",
    "                \"label\": \"relevant\",\n",
    "                \"topic\": topic\n",
    "            })\n",
    "            \n",
    "            stats[topic][\"rel_years\"].extend(doc.get('years', []))\n",
    "            stats[topic][\"rel_ents\"].extend(doc.get('named_entities', []))\n",
    "\n",
    "        noise_count = 0\n",
    "        while noise_count < 10:\n",
    "            candidate = random.choice(ALL_DOCS)\n",
    "            c_id = candidate.get('id', str(random.randint(10000, 99999)))\n",
    "            \n",
    "            if c_id not in relevant_ids:\n",
    "                dataset.append({\n",
    "                    \"id\": c_id,\n",
    "                    \"text\": candidate.get('text', '')[:200] + \"...\",\n",
    "                    \"label\": \"noise\",\n",
    "                    \"topic\": topic\n",
    "                })\n",
    "                noise_count += 1\n",
    "                \n",
    "                stats[topic][\"noise_years\"].extend(candidate.get('years', []))\n",
    "                stats[topic][\"noise_ents\"].extend(candidate.get('named_entities', []))\n",
    "\n",
    "    return dataset, stats\n",
    "\n",
    "benchmark_ds, benchmark_stats = generate_benchmark_dataset()\n",
    "\n",
    "print(f\"\\ Wygenerowano {len(benchmark_ds)} rekordów.\")\n",
    "print(\"Przykładowe 2 rekordy:\")\n",
    "print(json.dumps(benchmark_ds[:2], indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\nAnaliza metadanych:\")\n",
    "for topic, data in benchmark_stats.items():\n",
    "    print(f\"\\nTemat: {topic}\")\n",
    "    \n",
    "    top_rel_years = Counter(data['rel_years']).most_common(3)\n",
    "    top_noise_years = Counter(data['noise_years']).most_common(3)\n",
    "    \n",
    "    top_rel_ents = Counter(data['rel_ents']).most_common(3)\n",
    "    top_noise_ents = Counter(data['noise_ents']).most_common(3)\n",
    "    \n",
    "    print(f\"   [Trafne] Typowe lata: {top_rel_years} | Typowe encje: {top_rel_ents}\")\n",
    "    print(f\"   [Szum]   Typowe lata: {top_noise_years} | Typowe encje: {top_noise_ents}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45605b67",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Na podstawie zebranych statystyk można zauważyć kluczowe różnice.\n",
    "\n",
    "1. Encje:\n",
    "\n",
    "    Relevant: w dokumentach na tematy \"odpowiedzialność\" i \"zaufanie\" pojawiają się encje związane z organizacjami międzynarodowymi np. European Commission, technologią np. DAO - organizacje zaufania cyfrowego oraz pojęciami abstrakcyjnymi błędnie zaklasyfikowanymi jako nazwy własne np. samostanowienie.\n",
    "\n",
    "    Noise: w dokumentach nietrafnych zdecydowanie dominują konkretne lokalizacje geograficzne niezwiązane z tematem np. Szkocja, Archidiecezja Glasgow, Nadrenia Północna-Westfalia, Tatry. Są to często artykuły newsowe lub turystyczne, które przypadkowo zawierały poszukiwane słowo.\n",
    "\n",
    "2. Lata (Years):\n",
    "\n",
    "    W analizowanych próbkach dokumenty trafne często dotyczą lat nowszych np. 2020 w kontekście przywództwa/zaufania, co może wiązać się z publikacjami na temat kryzysów lub pandemii.\n",
    "\n",
    "    Dokumenty typu \"szum\" rozkładają się losowo, często wskazując na lata historyczne lub nieistotne dla bieżącej analizy np. 2002, 2006.\n",
    "\n",
    "Istnieje silna korelacja semantyczna w metadanych. Wykluczenie dokumentów zawierających encje typowo geograficzne gdy nie szukamy lokalizacji oraz filtrowanie po roku pozwala skutecznie odsiać szum informacyjny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a45dcd1",
   "metadata": {},
   "source": [
    "## 6. RAG \n",
    "\n",
    "W ostatnim etapie połączono wszystkie moduły w jeden spójny system RAG.\n",
    "\n",
    "Wybrany problem badawczy:\n",
    "- \"Jak zmienia się narracja o przywództwie i liderach w tekstach opublikowanych po roku 2020?\"\n",
    "\n",
    "Schemat Pipeline'u:\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    User[Użytkownik] -->|Pytanie: 'Liderzy po 2020'| Brain[Agent Brain: Ekstrakcja]\n",
    "    \n",
    "    subgraph Metadata Extraction\n",
    "    Brain -->|LLM/Regex| Filters{Filtry?}\n",
    "    Filters -->|Lata >= 2020| DateFilter[Filtr Dat]\n",
    "    Filters -->|Temat: 'Liderzy'| Query[Query Vector]\n",
    "    end\n",
    "    \n",
    "    subgraph Retrieval Layer\n",
    "    DateFilter & Query --> Hybrid[Hybrid Search Engine]\n",
    "    Hybrid -->|ES + Qdrant| Docs[Dokumenty Relevant]\n",
    "    end\n",
    "    \n",
    "    subgraph Generation Layer\n",
    "    Docs -->|Kontekst| Prompt[Prompt RAG]\n",
    "    Prompt -->|Ollama: Gemma2| Answer[Finalna Odpowiedź]\n",
    "    end\n",
    "    \n",
    "    Answer --> User"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67706e47",
   "metadata": {},
   "source": [
    "### 6.1 Zadanie – QUALITY LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d4f45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uruchamiam Quality Loop.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr</th>\n",
       "      <th>Zapytanie</th>\n",
       "      <th>Znaleziony Tekst (Top 1)</th>\n",
       "      <th>Metadane (Lata)</th>\n",
       "      <th>Metadane (Encje)</th>\n",
       "      <th>Wymagany filtr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wydarzenia i kryzysy w 2020 roku</td>\n",
       "      <td>Wydział I Nauk Humanistycznych i Społecznych W roku 2020 Wydział I przyznał następujące nagrody i wy...</td>\n",
       "      <td>[2020]</td>\n",
       "      <td>['Wydział I', 'Wydział I Nauk Humanistycznych i Społecznych']</td>\n",
       "      <td>Lata: [2020] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Technologia przed rokiem 2015</td>\n",
       "      <td>O Biznes-Host.pl RobimySEO zaczął obserwować Biznes-Host.pl Grudzień 29, 2015 Biznes-Host.pl zaczął ...</td>\n",
       "      <td>[2012, 2015]</td>\n",
       "      <td>['Biznes - Host', '##ty', 'Biznes']</td>\n",
       "      <td>Lata: [2010, 2011, 2012, 2013, 2014] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Przyszłość i plany na 2023</td>\n",
       "      <td>Brak wyników</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>Lata: [2023] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Sytuacja gospodarcza w Polsce</td>\n",
       "      <td>Konfederacja Lewiatan – najbardziej wpływowa polska organizacja biznesowa, reprezentująca interesy p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Unii Europejskiej', 'Konfederacja Lewiatan', 'Polsce']</td>\n",
       "      <td>Lata: [] | Encje: ['Polsce']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Działania Unii Europejskiej</td>\n",
       "      <td>Konfederacja Lewiatan – najbardziej wpływowa polska organizacja biznesowa, reprezentująca interesy p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Unii Europejskiej', 'Konfederacja Lewiatan', 'Polsce']</td>\n",
       "      <td>Lata: [] | Encje: ['Unii Europejskiej']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Co słychać w Warszawie?</td>\n",
       "      <td>Wdrożenie ustawy PAD - Andrzej Lanc - 27 czerwca 2018 w Warszawie Rekomendacja D-SKOK Standardy wewn...</td>\n",
       "      <td>[2018]</td>\n",
       "      <td>['Grzegorz Banaś', 'Andrzej Lanc', 'Warszawie']</td>\n",
       "      <td>Lata: [] | Encje: ['Warszawie']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Definicja zaufania społecznego</td>\n",
       "      <td>Definicja człowieczeństwa skupia się w pojęciu homo sapiens – człowieka myślącego, który realizuje s...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['homo sapiens']</td>\n",
       "      <td>Lata: [] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Cechy dobrego lidera</td>\n",
       "      <td>Mają one dotyczyć osób zaangażowanych w skazanie na pobyt w kolonii karnej lidera rosyjskiej opozycj...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Aleksieja Nawalnego']</td>\n",
       "      <td>Lata: [] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sprzedaż samochodów i rynki</td>\n",
       "      <td>Obecnie zakaz palenia e papierosów obowiązuje... 2018-03-23|Kategoria: Sprzedaż Interntowa / Inne Sk...</td>\n",
       "      <td>[2017, 2018]</td>\n",
       "      <td>['Inne Sklepy', 'Inne Sklepy Majic Paints', '##rzedaż Interntowa']</td>\n",
       "      <td>Lata: [2018] | Encje: []</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Bezpieczeństwo danych osobowych</td>\n",
       "      <td>Administrator danych osobowych Administratorem Twoich danych osobowych jest \"Eversun\" Dawid Sipowicz...</td>\n",
       "      <td>[]</td>\n",
       "      <td>['Sopot', 'Dawid Sipowicz']</td>\n",
       "      <td>Lata: [] | Encje: []</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Nr                         Zapytanie  \\\n",
       "0   1  Wydarzenia i kryzysy w 2020 roku   \n",
       "1   2     Technologia przed rokiem 2015   \n",
       "2   3        Przyszłość i plany na 2023   \n",
       "3   4     Sytuacja gospodarcza w Polsce   \n",
       "4   5       Działania Unii Europejskiej   \n",
       "5   6           Co słychać w Warszawie?   \n",
       "6   7    Definicja zaufania społecznego   \n",
       "7   8              Cechy dobrego lidera   \n",
       "8   9       Sprzedaż samochodów i rynki   \n",
       "9  10   Bezpieczeństwo danych osobowych   \n",
       "\n",
       "                                                                                  Znaleziony Tekst (Top 1)  \\\n",
       "0  Wydział I Nauk Humanistycznych i Społecznych W roku 2020 Wydział I przyznał następujące nagrody i wy...   \n",
       "1  O Biznes-Host.pl RobimySEO zaczął obserwować Biznes-Host.pl Grudzień 29, 2015 Biznes-Host.pl zaczął ...   \n",
       "2                                                                                             Brak wyników   \n",
       "3  Konfederacja Lewiatan – najbardziej wpływowa polska organizacja biznesowa, reprezentująca interesy p...   \n",
       "4  Konfederacja Lewiatan – najbardziej wpływowa polska organizacja biznesowa, reprezentująca interesy p...   \n",
       "5  Wdrożenie ustawy PAD - Andrzej Lanc - 27 czerwca 2018 w Warszawie Rekomendacja D-SKOK Standardy wewn...   \n",
       "6  Definicja człowieczeństwa skupia się w pojęciu homo sapiens – człowieka myślącego, który realizuje s...   \n",
       "7  Mają one dotyczyć osób zaangażowanych w skazanie na pobyt w kolonii karnej lidera rosyjskiej opozycj...   \n",
       "8  Obecnie zakaz palenia e papierosów obowiązuje... 2018-03-23|Kategoria: Sprzedaż Interntowa / Inne Sk...   \n",
       "9  Administrator danych osobowych Administratorem Twoich danych osobowych jest \"Eversun\" Dawid Sipowicz...   \n",
       "\n",
       "  Metadane (Lata)  \\\n",
       "0          [2020]   \n",
       "1    [2012, 2015]   \n",
       "2               -   \n",
       "3              []   \n",
       "4              []   \n",
       "5          [2018]   \n",
       "6              []   \n",
       "7              []   \n",
       "8    [2017, 2018]   \n",
       "9              []   \n",
       "\n",
       "                                                     Metadane (Encje)  \\\n",
       "0       ['Wydział I', 'Wydział I Nauk Humanistycznych i Społecznych']   \n",
       "1                                 ['Biznes - Host', '##ty', 'Biznes']   \n",
       "2                                                                   -   \n",
       "3            ['Unii Europejskiej', 'Konfederacja Lewiatan', 'Polsce']   \n",
       "4            ['Unii Europejskiej', 'Konfederacja Lewiatan', 'Polsce']   \n",
       "5                     ['Grzegorz Banaś', 'Andrzej Lanc', 'Warszawie']   \n",
       "6                                                    ['homo sapiens']   \n",
       "7                                             ['Aleksieja Nawalnego']   \n",
       "8  ['Inne Sklepy', 'Inne Sklepy Majic Paints', '##rzedaż Interntowa']   \n",
       "9                                         ['Sopot', 'Dawid Sipowicz']   \n",
       "\n",
       "                                     Wymagany filtr  \n",
       "0                          Lata: [2020] | Encje: []  \n",
       "1  Lata: [2010, 2011, 2012, 2013, 2014] | Encje: []  \n",
       "2                          Lata: [2023] | Encje: []  \n",
       "3                      Lata: [] | Encje: ['Polsce']  \n",
       "4           Lata: [] | Encje: ['Unii Europejskiej']  \n",
       "5                   Lata: [] | Encje: ['Warszawie']  \n",
       "6                              Lata: [] | Encje: []  \n",
       "7                              Lata: [] | Encje: []  \n",
       "8                          Lata: [2018] | Encje: []  \n",
       "9                              Lata: [] | Encje: []  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rag.retrieval.search_engine import hybrid_search\n",
    "\n",
    "test_cases = [\n",
    "    {\"query\": \"Wydarzenia i kryzysy w 2020 roku\", \"years\": [2020], \"entities\": []},\n",
    "    {\"query\": \"Technologia przed rokiem 2015\", \"years\": [2010, 2011, 2012, 2013, 2014], \"entities\": []},\n",
    "    {\"query\": \"Przyszłość i plany na 2023\", \"years\": [2023], \"entities\": []},\n",
    "    \n",
    "    {\"query\": \"Sytuacja gospodarcza w Polsce\", \"years\": [], \"entities\": [\"Polsce\"]},\n",
    "    {\"query\": \"Działania Unii Europejskiej\", \"years\": [], \"entities\": [\"Unii Europejskiej\"]},\n",
    "    {\"query\": \"Co słychać w Warszawie?\", \"years\": [], \"entities\": [\"Warszawie\"]},\n",
    "    \n",
    "    {\"query\": \"Definicja zaufania społecznego\", \"years\": [], \"entities\": []},\n",
    "    {\"query\": \"Cechy dobrego lidera\", \"years\": [], \"entities\": []},\n",
    "    \n",
    "    {\"query\": \"Sprzedaż samochodów i rynki\", \"years\": [2018], \"entities\": []}, \n",
    "    {\"query\": \"Bezpieczeństwo danych osobowych\", \"years\": [], \"entities\": []}\n",
    "]\n",
    "\n",
    "results_quality = []\n",
    "\n",
    "print(\"Uruchamiam Quality Loop.\")\n",
    "\n",
    "for i, case in enumerate(test_cases):\n",
    "    q = case['query']\n",
    "    filters = {}\n",
    "    if case['years']: filters['years'] = case['years']\n",
    "    if case['entities']: filters['named_entities'] = case['entities']\n",
    "    \n",
    "    docs = hybrid_search(q, filters=filters, limit=1) \n",
    "    top_doc = docs[0] if docs else None\n",
    "    \n",
    "    if top_doc:\n",
    "        doc_text = top_doc.get('text', '')[:100] + \"...\"\n",
    "        doc_years = str(top_doc.get('years', []))\n",
    "        doc_ents = str(top_doc.get('named_entities', [])[:3]) \n",
    "    else:\n",
    "        doc_text = \"Brak wyników\"\n",
    "        doc_years = \"-\"\n",
    "        doc_ents = \"-\"\n",
    "\n",
    "    results_quality.append({\n",
    "        \"Nr\": i+1,\n",
    "        \"Zapytanie\": q,\n",
    "        \"Znaleziony Tekst (Top 1)\": doc_text,\n",
    "        \"Metadane (Lata)\": doc_years,\n",
    "        \"Metadane (Encje)\": doc_ents,\n",
    "        \"Wymagany filtr\": f\"Lata: {case['years']} | Encje: {case['entities']}\"\n",
    "    })\n",
    "\n",
    "df_q = pd.DataFrame(results_quality)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(df_q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5962b10",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "| Zapytanie | Label | Encje | Daty | Halucynacje / Uwagi | Ocena (0-2) |\n",
    "| :--- | :--- | :--- | :--- | :--- | :--- |\n",
    "| **1. Wydarzenia 2020** | **Relevant** | *Wydział I* | *[2020]* | Brak. System precyzyjnie znalazł raport z roku 2020. | **2** |\n",
    "| **2. Technologia < 2015** | **Relevant** | *Biznes-Host* | *[2012, 2015]* | Dokument zawiera rok 2012, choć w tekście pojawia się też 2015. Temat pasuje. | **2** |\n",
    "| **3. Przyszłość 2023** | **Brak** | *-* | *-* | **Brak wyników.** Korpus `CulturaX` kończy się przed 2023 rokiem, więc system słusznie nic nie wymyślił. | **-** |\n",
    "| **4. Gospodarka (Polska)** | **Relevant** | *Polsce, Konfederacja Lewiatan* | *-* | Idealne trafienie. Encja \"Polsce\" oraz organizacja biznesowa. | **2** |\n",
    "| **5. Unia Europejska** | **Relevant** | *Unii Europejskiej* | *-* | To samo co wyżej - encja została poprawnie wykorzystana do znalezienia kontekstu. | **2** |\n",
    "| **6. Warszawa** | **Relevant** | *Warszawie* | *[2018]* | Znaleziono newsa o ustawie/wydarzeniu w Warszawie. Kontekst geograficzny zachowany. | **2** |\n",
    "| **7. Definicja zaufania** | **Noise** | *homo sapiens* | *-* | **Błąd semantyczny.** System znalazł \"definicję człowieczeństwa\" zamiast \"zaufania\". Wektory były zbyt blisko ogólnych pojęć filozoficznych. | **1** |\n",
    "| **8. Cechy lidera** | **Noise** | *Aleksieja Nawalnego* | *-* | **Błąd kontekstu.** Znaleziono słowo \"lider\", ale w kontekście politycznym/karnym, a nie cech przywódczych. Klasyczny problem wieloznaczności słów. | **1** |\n",
    "| **9. Sprzedaż aut 2018** | **Noise** | *Inne Sklepy* | *[2018]* | Zgodność roku i słowa \"sprzedaż\", ale temat dotyczy e-papierosów, a nie aut. | **1** |\n",
    "| **10. Bezpieczeństwo danych** | **Relevant** | *Eversun* | *-* | Trafienie w klauzulę RODO. | **2** |\n",
    "\n",
    "**Podsumowanie**\n",
    "- **Skuteczność filtrów:** mechanizm `hybrid_search` bezbłędnie egzekwuje filtry. Nie zwrócono dokumentów z błędnego roku ani z błędną encją. W przypadku braku danych (rok 2023) system uczciwie zwrócił pusty wynik.\n",
    "- **Problemy semantyczne:** Wyszukiwanie wektorowe przy pojęciach abstrakcyjnych ma tendencję do kierowania w stronę newsów politycznych lub innych definicji. Wymagałoby to zastosowania rerankera w kolejnym etapie projektu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae78f3c4",
   "metadata": {},
   "source": [
    "#### 6.2 Zadanie – Memory as Knowledge Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce9f15fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Krok 1: Użytkownik pyta o brakujące dane.\n",
      "Zapisano intencję: 'Jakie są prognozy PKB na 2025 rok?' Czekam na dane: {'years': [2025], 'named_entities': ['PKB']}\n",
      "Krok 2: Wpada nowy dokument.\n",
      "Nowy dokument: 'Wzrost PKB w 2025 roku w Polsce prognozo.' [Rok: [2025]]\n",
      "   Dokument pasuje do oczekującego pytania: 'Jakie są prognozy PKB na 2025 rok?'.\n",
      "\n",
      "Powiadomienie dla użytkownika:\n",
      "   Znaleźliśmy nowe informacje dla Twojego pytania: Jakie są prognozy PKB na 2025 rok?'\n"
     ]
    }
   ],
   "source": [
    "from rag.reasoning.memory import KnowledgeMemory\n",
    "\n",
    "memory = KnowledgeMemory()\n",
    "\n",
    "\n",
    "print(\" Krok 1: Użytkownik pyta o brakujące dane.\")\n",
    "memory.add_pending(\n",
    "    query=\"Jakie są prognozy PKB na 2025 rok?\", \n",
    "    filters={\"years\": [2025], \"named_entities\": [\"PKB\"]}\n",
    ")\n",
    "print(\"Krok 2: Wpada nowy dokument.\")\n",
    "incoming_doc = {\n",
    "    \"text\": \"Wzrost PKB w 2025 roku w Polsce prognozowany jest na poziomie 3%...\",\n",
    "    \"years\": [2025],\n",
    "    \"named_entities\": [\"PKB\", \"Polska\"]\n",
    "}\n",
    "\n",
    "triggered = memory.check_new_document(incoming_doc)\n",
    "\n",
    "if triggered:\n",
    "    print(\"\\nPowiadomienie dla użytkownika:\")\n",
    "    for t in triggered:\n",
    "        print(f\"   Znaleźliśmy nowe informacje dla Twojego pytania: {t['query']}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0057f47e",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Na podstawie powyższych logów system zadziałał poprawnie w modelu Event-Driven:\n",
    "1.  Rejestracja braku wiedzy: system poprawnie zidentyfikował brak danych dla zapytania o rok 2025 i zamiast halucynować, zapisał intencję w pamięci (`pending_queries`).\n",
    "2.  Dopasowanie: w momencie nadejścia nowego dokumentu (zawierającego rok `2025` i encję `PKB`), mechanizm `check_new_document` skutecznie powiązał go z oczekującym zapytaniem.\n",
    "3.  Reakcja: system automatycznie wyzwolił akcję powiadomienia, zamykając pętlę \"Quality Loop\".\n",
    "\n",
    "\n",
    "#### Odpowiedzi na pytania\n",
    "\n",
    "1. Jak system powinien obchodzić się z nowymi dokumentami?\n",
    "    System nie powinien przeszukiwać całej bazy historycznej przy każdym nowym dokumencie (byłoby to nieefektywne). Zamiast tego należy zastosować **Ingestion Hook**:\n",
    "    - Każdy nowy dokument wpadający do pipeline'u (np. z crawlera) jest \"skanowany\" w locie.\n",
    "    - Wyciągamy z niego metadane (Lata, Encje).\n",
    "    - Porównujemy je z \"lekką\" listą oczekujących zapytań (Pending Queries) przechowywaną w szybkiej pamięci (np. Redis).\n",
    "    - Jeśli metadane się pokrywają (np. *Dokument ma rok 2024* AND *Oczekujące zapytanie chce rok 2024*), oznaczamy zapytanie jako \"gotowe do ponowienia\".\n",
    "\n",
    "2. Jak RAG mógłby „przypomnieć sobie” o starych zapytaniach?\n",
    "    Proces przypominania powinien być asynchroniczny, aby nie blokować indeksowania danych:\n",
    "    1.  Zmiana Stanu: gdy Ingestion Hook wykryje dopasowanie, zmienia status zapytania z `waiting` na `retry_ready`.\n",
    "    2.  Worker: ssobny proces działający w tle lub okresowo jako CRON pobiera zapytania o statusie `retry_ready`.\n",
    "    3.  Weryfikacja: worker wykonuje pełne wyszukiwanie RAG z użyciem nowego dokumentu. Jeśli Confidence Score odpowiedzi jest wysoki, uznaje problem za rozwiązany.\n",
    "\n",
    "3. Czy system powinien powiadomić użytkownika?\n",
    "    Zdecydowanie tak. To kluczowa cecha odróżniająca inteligentnego agenta od zwykłej wyszukiwarki.\n",
    "    - Kanał: e-mail, powiadomienie push lub wiadomość na czacie w zależności od interfejsu.\n",
    "    - Format: \"Cześć! Pytałeś ostatnio o [Temat]. Właśnie przetworzyliśmy nowy raport, który zawiera odpowiedź na Twoje pytanie: [Link/Odpowiedź].\"\n",
    "    - Wartość: buduje to zaufanie użytkownika do systemu, który \"pamięta\" i \"pracuje w tle\", nawet gdy użytkownik nie jest aktywny."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a80ff8",
   "metadata": {},
   "source": [
    "### 6.3 Zadania związane z promptami dla NER i dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc587936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ładowanie modelu NER: Babelscape/wikineural-multilingual-ner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model NER gotowy.\n",
      "Tekst: Podczas szczytu w Davos, Satya Nadella, CEO Microsoftu, ogłosił nową strategię AI. \n",
      "W kuluarach rozmawiał z nim Jan Kowalski, analityk z Warszawy, który przyglądał się zmianom.\n",
      "\n",
      "1. Model NER\n",
      "['Jan Kowalski', 'Warszawy', 'Davos', 'Satya Nadella', 'Microsoft']\n",
      "\n",
      "2. LLM - wariat prosty\n",
      "{\n",
      "  \"persons\": [\n",
      "    \"Satya Nadella\",\n",
      "    \"Jan Kowalski\"\n",
      "  ],\n",
      "  \"organizations\": [\n",
      "    \"Microsoftu\"\n",
      "  ],\n",
      "  \"locations\": [\n",
      "    \"Davos\",\n",
      "    \"Warszawa\"\n",
      "  ]\n",
      "}\n",
      "\n",
      "3. LLM wariant skomplikowany\n",
      "{\n",
      "  \"leaders\": [\n",
      "    \"Satya Nadella\"\n",
      "  ],\n",
      "  \"organizations\": [\n",
      "    \"Microsoftu\"\n",
      "  ],\n",
      "  \"locations\": [\n",
      "    \"Davos\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "from rag.metadata.ner import NERExtractor\n",
    "\n",
    "ner_model = NERExtractor()\n",
    "\n",
    "def extract_with_prompt(text, prompt_type=\"simple\"):\n",
    "    if prompt_type == \"simple\":\n",
    "        system_prompt = \"\"\"\n",
    "        Wyodrębnij z tekstu wszystkie nazwane encje:\n",
    "        - persons: Imię i nazwisko\n",
    "        - organizations: Firmy, instytucje\n",
    "        - locations: Miasta, kraje\n",
    "        \n",
    "        Zwróć TYLKO JSON w formacie:\n",
    "        { \"persons\": [], \"organizations\": [], \"locations\": [] }\n",
    "        \"\"\"\n",
    "    else:\n",
    "        system_prompt = \"\"\"\n",
    "        Jesteś ekspertem od analizy przywództwa. Z tekstu wyodrębnij:\n",
    "        - leaders: Osoby pełniące rolę przywódczą np. prezesi, dyrektorzy, liderzy opinii.\n",
    "        - organizations: Organizacje, którymi zarządzają.\n",
    "        - locations: Miejsca kluczowe dla kontekstu np. siedziba, miejsce konferencji.\n",
    "        \n",
    "        Ignoruj osoby, które nie są liderami np. zwykli pracownicy, świadkowie.\n",
    "        \n",
    "        Zwróć TYLKO JSON w formacie:\n",
    "        { \"leaders\": [], \"organizations\": [], \"locations\": [] }\n",
    "        \"\"\"\n",
    "\n",
    "    full_prompt = f\"{system_prompt}\\n\\nTekst: {text}\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gemma2:2b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": full_prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0.0}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/chat\", json=payload, timeout=60)\n",
    "        content = response.json()['message']['content']\n",
    "        clean_json = re.sub(r'```json|```', '', content).strip()\n",
    "        return json.loads(clean_json)\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "sample_text = \"\"\"\n",
    "Podczas szczytu w Davos, Satya Nadella, CEO Microsoftu, ogłosił nową strategię AI. \n",
    "W kuluarach rozmawiał z nim Jan Kowalski, analityk z Warszawy, który przyglądał się zmianom.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"Tekst: {sample_text.strip()}\\n\")\n",
    "\n",
    "print(\"1. Model NER\")\n",
    "print(ner_model.extract(sample_text))\n",
    "\n",
    "print(\"\\n2. LLM - wariat prosty\")\n",
    "print(json.dumps(extract_with_prompt(sample_text, \"simple\"), indent=2, ensure_ascii=False))\n",
    "\n",
    "print(\"\\n3. LLM wariant skomplikowany\")\n",
    "print(json.dumps(extract_with_prompt(sample_text, \"contextual\"), indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53cede81",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "1. NER \n",
    "\n",
    "    Jest \"zachłanny\". Złapał wszystko - Jana i Satyę - ale wrzucił ich do jednego worka. Dla modelu BERT Jan Kowalski i CEO Microsoftu to po prostu PER.\n",
    "\n",
    "2. LLM prosty\n",
    "\n",
    "    Zrobił to samo co NER, ale ładnie posortował na kategorie. Zamienił \"Warszawy\" na mianownik \"Warszawa\" czego zwykły NER często nie robi bez lemmatyzatora.\n",
    "\n",
    "3. LLM kontekstowy \n",
    "\n",
    "    Zrozumiał, że Jan Kowalski nie jest liderem, tylko analitykiem, i wyrzucił go z listy leaders. Zrozumiał też, że Warszawa nie jest kluczowa dla kontekstu przywództwa w tym zdaniu - nie była miejscem szczytu, tylko pochodzenia analityka - więc ją pominął."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b89caf",
   "metadata": {},
   "source": [
    "### 6.4 Prompt dla dat w kontekście RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ade2a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytanie: Jakie zmiany w podatkach wprowadzono w 2022 roku?\n",
      "\n",
      "Rozpoczynam reranking .\n",
      "\n",
      "   Doc ID: 1\n",
      "   Daty: []\n",
      "   Relevant: False | Wyjaśnienie: W tekście nie ma informacji o zmianach podatkowych w 2022 roku. Tekst dotyczy wprowadzenia ulgi na dzieci w 2015 roku.\n",
      "   Score: 0.95 -> 0.45\n",
      "\n",
      "   Doc ID: 2\n",
      "   Daty: ['2022-01-01']\n",
      "   Relevant: True | Wyjaśnienie: Data ta jest istotna dla pytania użytkownika, ponieważ zawiera datę w której wprowadzono nowy system podatkowy.\n",
      "   Score: 0.92 -> 0.92\n",
      "\n",
      "   Doc ID: 3\n",
      "   Daty: []\n",
      "   Relevant: False | Wyjaśnienie: Brak daty w tekście. Pytanie dotyczy konkretnych zmian w podatkach w roku 2022, a tekst nie zawiera informacji o konkretnej dacie.\n",
      "   Score: 0.8 -> 0.30\n",
      "\n",
      "Finalny ranking dokumentów:\n",
      "   [0.92] Doc 2: Nowy Ład podatkowy wchodzi w życie od stycznia 2022 roku.\n",
      "   [0.45] Doc 1: W 2015 roku wprowadzono ulgę na dzieci, która zmieniła system podatkowy.\n",
      "   [0.30] Doc 3: Ministerstwo Finansów planuje zmiany. (Brak daty)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import re\n",
    "\n",
    "def analyze_date_relevance(text, question):\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Jesteś analitykiem czasu w dokumentach. Twoim zadaniem jest:\n",
    "    1. Wyodrębnić wszystkie daty z poniższego tekstu.\n",
    "    2. Określić, czy te daty są istotne dla odpowiedzi na pytanie użytkownika.\n",
    "    \n",
    "    Pytanie użytkownika: \"{question}\"\n",
    "    \n",
    "    Tekst do analizy: \"{text}\"\n",
    "    \n",
    "    Zwróć TYLKO JSON w formacie:\n",
    "    {{\n",
    "      \"extracted_dates\": [\"YYYY-MM-DD\", \"YYYY\", ...],\n",
    "      \"is_relevant\": true/false,\n",
    "      \"explanation\": \"Krótkie uzasadnienie dlaczego pasuje lub nie.\"\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": \"gemma2:2b\",\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\"temperature\": 0.0}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(\"http://localhost:11434/api/chat\", json=payload, timeout=60)\n",
    "        content = response.json()['message']['content']\n",
    "        clean_json = re.sub(r'```json|```', '', content).strip()\n",
    "        return json.loads(clean_json)\n",
    "    except Exception as e:\n",
    "        return {\"extracted_dates\": [], \"is_relevant\": True, \"explanation\": \"Error: \" + str(e)}\n",
    "\n",
    "question = \"Jakie zmiany w podatkach wprowadzono w 2022 roku?\"\n",
    "\n",
    "retrieved_docs = [\n",
    "    {\n",
    "        \"id\": 1, \n",
    "        \"text\": \"W 2015 roku wprowadzono ulgę na dzieci, która zmieniła system podatkowy.\",\n",
    "        \"base_score\": 0.95  \n",
    "    },\n",
    "    {\n",
    "        \"id\": 2, \n",
    "        \"text\": \"Nowy Ład podatkowy wchodzi w życie od stycznia 2022 roku.\",\n",
    "        \"base_score\": 0.92\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3, \n",
    "        \"text\": \"Ministerstwo Finansów planuje zmiany. (Brak daty)\",\n",
    "        \"base_score\": 0.80\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Pytanie: {question}\\n\")\n",
    "print(\"Rozpoczynam reranking .\\n\")\n",
    "\n",
    "reranked_docs = []\n",
    "\n",
    "for doc in retrieved_docs:\n",
    "    analysis = analyze_date_relevance(doc['text'], question)\n",
    "    \n",
    "    final_score = doc['base_score']\n",
    "    penalty = 0.0\n",
    "    \n",
    "    if not analysis['is_relevant']:\n",
    "        penalty = 0.5\n",
    "        final_score -= penalty\n",
    "        \n",
    "    doc['analysis'] = analysis\n",
    "    doc['final_score'] = final_score\n",
    "    reranked_docs.append(doc)\n",
    "    \n",
    "    print(f\"   Doc ID: {doc['id']}\")\n",
    "    print(f\"   Daty: {analysis.get('extracted_dates')}\")\n",
    "    print(f\"   Relevant: {analysis.get('is_relevant')} | Wyjaśnienie: {analysis.get('explanation')}\")\n",
    "    print(f\"   Score: {doc['base_score']} -> {final_score:.2f}\\n\")\n",
    "\n",
    "reranked_docs.sort(key=lambda x: x['final_score'], reverse=True)\n",
    "\n",
    "print(\"Finalny ranking dokumentów:\")\n",
    "for doc in reranked_docs:\n",
    "    print(f\"   [{doc['final_score']:.2f}] Doc {doc['id']}: {doc['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ff82",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Mechanizm poprawnie zmienił kolejność dokumentów, naprawiając błędy standardowego wyszukiwania.\n",
    "\n",
    "1. Eliminacja \"starych newsów\"\n",
    "    Dokument o uldze z 2015 roku miał pierwotnie najwyższy wynik (`0.95`) ze względu na idealne dopasowanie słów kluczowych. LLM poprawnie zidentyfikował, że kontekst czasowy jest sprzeczny z pytaniem. Nałożono karę punktową -0.5, degradując dokument na niższą pozycję (`0.45`).\n",
    "\n",
    "2. Promocja właściwego kontekstu\n",
    "    Dokument o \"Nowym Ładzie\" zawierał poszukiwaną datę 2022. LLM oznaczył go jako `Relevant: True`. Dokument awansował na 1. miejsce w rankingu (`0.92`), stając się głównym źródłem dla odpowiedzi.\n",
    "\n",
    "3. Surowa ocena braku danych\n",
    "    Dokument bez dat został oceniony jako nieistotny dla tak precyzyjnego zapytania. Pokazuje to, że LLM potrafi odróżnić ogólniki od konkretów.\n",
    "\n",
    "#### Wnioski\n",
    "\n",
    "Zastosowanie LLM do weryfikacji metadanych na etapie rerankingu pozwala uniknąć typowego błędu systemów RAG, czyli generowania odpowiedzi na podstawie nieaktualnych, ale leksykalnie podobnych dokumentów."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b3d843",
   "metadata": {},
   "source": [
    "### 6.5 Finalny prototyp – agent badawczy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cfc384b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test A: Sukces\n",
      "\n",
      "Rozpoczynam proces dla: 'Co działo się w Warszawie w 2018 roku?'\n",
      "   Filtry: {'years': [2018], 'named_entities': ['Warszawa']}\n",
      "   Znaleziono 2 kandydatów.\n",
      "   Tworzę odpowiedź z 2 źródeł.\n",
      "\n",
      "Wynik: W 2018 roku Warszawa była popularnym miejscem dla inwestorów, którzy planowali zwiększyć swoją aktywność. \n",
      "\n",
      "\n",
      "Test B: Pamięć\n",
      "\n",
      "Rozpoczynam proces dla: 'Jaka będzie inflacja w Polsce w 2030 roku?'\n",
      "   Filtry: {'years': [2030], 'named_entities': ['Polska', '']}\n",
      "   Znaleziono 0 kandydatów.\n",
      "   Brak danych. Zapisuję w pamięci.\n",
      "Zapisano intencję: 'Jaka będzie inflacja w Polsce w 2030 roku?' Czekam na dane: {'years': [2030], 'named_entities': ['Polska', '']}\n",
      "\n",
      "Wynik: Nie posiadam obecnie tych informacji. Zapisałem Twoje pytanie i powiadomię Cię, gdy pojawią się nowe dane.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from rag.reasoning.research_agent import ResearchAgent\n",
    "\n",
    "agent = ResearchAgent()\n",
    "\n",
    "\n",
    "\n",
    "print(\"Test A: Sukces\")\n",
    "response_success = agent.solve(\"Co działo się w Warszawie w 2018 roku?\")\n",
    "print(f\"\\nWynik: {response_success}\\n\")\n",
    "\n",
    "print(\"Test B: Pamięć\")\n",
    "response_memory = agent.solve(\"Jaka będzie inflacja w Polsce w 2030 roku?\")\n",
    "print(f\"\\nWynik: {response_memory}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfe0002",
   "metadata": {},
   "source": [
    "#### Wyniki\n",
    "\n",
    "Przeprowadzone testy potwierdzają pełną funkcjonalność systemu `ResearchAgent`:\n",
    "\n",
    "1. Skuteczność filtracji - Test A\n",
    "\n",
    "    Agent poprawnie wyekstrahował metadane - `2018`, `Warszawa`. Wyszukiwarka hybrydowa znalazła pasujące dokumenty. LLM wygenerował odpowiedź opartą na faktach \"Warszawa była popularnym miejscem dla inwestorów...\".\n",
    "\n",
    "2. Autonomia i pamięć - Test B\n",
    "\n",
    "    Agent rozpoznał zapytanie o przyszłość `2030`, której nie ma w korpusie `CulturaX`. Zamiast generować halucynacje, system przerwał proces generowania na etapie retrieval. Zapytanie zostało automatycznie zapisane w `KnowledgeMemory` z odpowiednimi tagami, co umożliwi powiadomienie użytkownika w przyszłości.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39056e28",
   "metadata": {},
   "source": [
    "## 7. Wnioski końcowe\n",
    "\n",
    "### Które procedury zadziałały najlepiej\n",
    "\n",
    "- Hybrid Search: najlepsza metoda retrievalu. Wektory znajdowały sens, a słowa kluczowe naprawiały precyzję przy nazwach własnych.\n",
    "\n",
    "- Filtracja twarda: zastosowanie metadanych na poziomie bazy danych dało 100% skuteczność w eliminowaniu dokumentów spoza zakresu czasowego.\n",
    "\n",
    "- Active Memory: mechanizm odkładania trudnych pytań \"na później\" okazał się skuteczniejszą strategią niż próba generowania odpowiedzi na siłę.\n",
    "\n",
    "### Kiedy NER i daty naprawdę pomogły\n",
    "\n",
    "- Ujednoznacznienie kontekstu: przy zapytaniu o \"Warszawę\", dodanie encji LOC: Warszawa pozwoliło wyeliminować dokumenty, gdzie słowo to padało przypadkowo np. w adresie siedziby firmy w stopce, a skupić się na tekstach o mieście.\n",
    "\n",
    "- Podróż w czasie: przy zapytaniu o \"podatki w 2022\", mechanizm weryfikacji dat uratował system przed podaniem informacji o podatkach z 2015 roku, które były leksykalnie bardzo podobne, ale merytorycznie błędne.\n",
    "\n",
    "- Odsiewanie szumu: w benchmarku abstrakcyjnym, filtry encji pozwoliły oddzielić artykuły psychologiczne/biznesowe od ogłoszeń i spamu."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
